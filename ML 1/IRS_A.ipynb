{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 IRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information retrieval is the process of obtaining information system resources that are relevant to an information need from a collection of those resources. The core purpose of this assignment is to give you the flavor of IRS. You need to follow some steps listed below and in the end, you'll be able to build your own small IRS. So, let's start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import os\n",
    "\n",
    "#I have used all text files in files folder in this IRS_A. I have define some functions and working with them in this whole IRS_A.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have 3 files containing data :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Contents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"This is my book\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f1.png?raw=true)\n",
    "![\"This is my pen\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f2.png?raw=true)\n",
    "![\"This is book is intersting\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f3.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 Create Files with Dummy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to create few files with dummy data of your own choice as shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Traverse Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, You have to traverse the directories and store all the files into a dict type variable(files_dict). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have intialized some variables, you can add more if required.\n",
    "\n",
    "file_count = 0             # file_count to count number of files\n",
    "files_dict = {}            # files_dic to store count of every file    \n",
    "unique_word_set = set()    # unique_word_set to store all the unique words in a set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code starts here   \n",
    "def countFiles():\n",
    "    folder_path = './files' #files folder in current working directory.\n",
    "    file_count = len(os.listdir(folder_path))\n",
    "    return file_count\n",
    "\n",
    "def dictionaryOfFiles():\n",
    "    for file in os.listdir('./files'):\n",
    "        if file.endswith('.txt'):\n",
    "                key = file\n",
    "                files_dict[key] = files_dict.get(key,0)+1 #if there is no value at that key default 0 will be set.\n",
    "    return files_dict\n",
    "#Your code ends here       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the count of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Number  of files\n",
      " 7\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTotal Number  of files\\n\", countFiles())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying Dictionary containing all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dictionary containing  files\n",
      " {'f1.txt': 1, 'f2.txt': 1, 'f3.txt': 1, 'f4.txt': 1, 'f5.txt': 1, 'f6.txt': 1, 'synonyms.txt': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDictionary containing  files\\n\", dictionaryOfFiles())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 Extract Unique Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write code to print all the unique words in every file and store them in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in every file\n",
      " {'society', 'instance', 'examine', 'Lahore', 'tome', 'Lahore.', 'sample', 'letter', 'dossier', 'my', 'bring', 'question', 'software', 'organization', 'best', 'the', 'forgotten', 'replacement', 'document', 'structure', 'obtain', 'machine', 'favorite', 'mislaid', 'amazing', 'system', 'author', 'at', 'draft', 'back', 'arrangement', 'read', 'interesting', 'am', 'Town', 'application', 'study', 'absorbing', 'missing', 'lost', ':', 'paper', 'platform', 'This', 'fascinating', 'features.', 'device', 'create', 'search', 'look', 'car', 'form', 'example', 'My', 'book', 'framework', 'illustration', 'Range', 'pen', 'publication', 'Hi', 'processor', 'I', 'for', 'file', 'demonstration', 'synonym', 'fetch', 'car.', 'record', 'Hassan', 'program', 'Rover', 'equivalent', 'write', 'fountain', 'retrieve', 'request', 'of', 'recover', 'app', 'ballpoint', 'report', ',', 'explore', 'inquiry', 'peruse', 'ink', 'best.', 'scan', 'volume', 'misplaced', 'novel', 'has', 'alternate', 'query', 'sheet', 'computer', 'Vogue', 'Bahria', 'compose', 'engaging', 'seek', 'is', 'substitute', 'intriguing', 'laptop'} \n",
      " count of files 7\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here  \n",
    "def wordsInFiles():\n",
    "      for file in os.listdir('./files'):\n",
    "        if file.endswith('.txt'):\n",
    "            file_path = os.path.join('./files', file) #ie complete path /files/f1.txt etc.\n",
    "            with open(file_path,'r') as f:\n",
    "                words = f.read().split() #creating list of words of each file may contain duplicate values\n",
    "                for word in words:          #iterating words list to fetch each word\n",
    "                    unique_word_set.add(word) #adding unique values to set\n",
    "      return unique_word_set #uniquewordse contains 1 , and 1 : as they are dealt a separate word because of indentation in synonyms.txt file\n",
    "\n",
    "print(f'Unique words in every file\\n {wordsInFiles()} \\n count of files {countFiles()}')\n",
    "\n",
    "\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o1.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 Create Term Document Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Term-Doc-matrix using Bag of word approach.and display its contents initially and finally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create Term doc matrix such that colmns will be unique words and all the files will be rows\n",
    "- Write code to count all the unique words appearances in all the files and store it in a dictionary for words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "dictionary of unique words \n",
      "{'society': 0, 'instance': 1, 'examine': 2, 'Lahore': 3, 'tome': 4, 'Lahore.': 5, 'sample': 6, 'letter': 7, 'dossier': 8, 'my': 9, 'bring': 10, 'question': 11, 'software': 12, 'organization': 13, 'best': 14, 'the': 15, 'forgotten': 16, 'replacement': 17, 'document': 18, 'structure': 19, 'obtain': 20, 'machine': 21, 'favorite': 22, 'mislaid': 23, 'amazing': 24, 'system': 25, 'author': 26, 'at': 27, 'draft': 28, 'back': 29, 'arrangement': 30, 'read': 31, 'interesting': 32, 'am': 33, 'Town': 34, 'application': 35, 'study': 36, 'absorbing': 37, 'missing': 38, 'lost': 39, ':': 40, 'paper': 41, 'platform': 42, 'This': 43, 'fascinating': 44, 'features.': 45, 'device': 46, 'create': 47, 'search': 48, 'look': 49, 'car': 50, 'form': 51, 'example': 52, 'My': 53, 'book': 54, 'framework': 55, 'illustration': 56, 'Range': 57, 'pen': 58, 'publication': 59, 'Hi': 60, 'processor': 61, 'I': 62, 'for': 63, 'file': 64, 'demonstration': 65, 'synonym': 66, 'fetch': 67, 'car.': 68, 'record': 69, 'Hassan': 70, 'program': 71, 'Rover': 72, 'equivalent': 73, 'write': 74, 'fountain': 75, 'retrieve': 76, 'request': 77, 'of': 78, 'recover': 79, 'app': 80, 'ballpoint': 81, 'report': 82, ',': 83, 'explore': 84, 'inquiry': 85, 'peruse': 86, 'ink': 87, 'best.': 88, 'scan': 89, 'volume': 90, 'misplaced': 91, 'novel': 92, 'has': 93, 'alternate': 94, 'query': 95, 'sheet': 96, 'computer': 97, 'Vogue': 98, 'Bahria': 99, 'compose': 100, 'engaging': 101, 'seek': 102, 'is': 103, 'substitute': 104, 'intriguing': 105, 'laptop': 106}\n",
      "dictionary of files\n",
      " {'f1.txt': 0, 'f2.txt': 1, 'f3.txt': 2, 'f4.txt': 3, 'f5.txt': 4, 'f6.txt': 5, 'synonyms.txt': 6}\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "def termMatrix():\n",
    "    files = countFiles()\n",
    "    term_matrix = np.zeros([files,len(unique_word_set)]) # creating a table of size m*n filling each [i,j] with 0\n",
    "    return term_matrix\n",
    "\n",
    "def dictionaryOfUniqueWords():\n",
    "    listOfUniqueWords = list(unique_word_set) #converting the following set to list so it can become iterateable\n",
    "    uniqueWords = dict() #creating adictionary to store key-value pairs ie uniqueWords and their indexes\n",
    "    for i in range(len(unique_word_set)):\n",
    "        key = listOfUniqueWords[i]\n",
    "        uniqueWords[key] = uniqueWords.get(key,0)+i #assigning dictionary uniqueWords, keys are words and indexes are their values\n",
    "    return uniqueWords\n",
    "\n",
    "def dictionaryOfFiles():\n",
    "    i = 0\n",
    "    fileDictionary = dict()\n",
    "    for file in os.listdir('./files'):\n",
    "        if file.endswith('.txt'):\n",
    "            key = file\n",
    "            fileDictionary[key] = fileDictionary.get(key,0)+i #assigning dictionary fileDictionary, keys are file name and indexes are their values.\n",
    "            i = i+1\n",
    "    return fileDictionary\n",
    "\n",
    "    \n",
    "\n",
    "print(termMatrix())\n",
    "print(f'dictionary of unique words \\n{dictionaryOfUniqueWords()}')\n",
    "print(f'dictionary of files\\n {dictionaryOfFiles()}')\n",
    "\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 Fill Term Document Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fill the term doc matrix by checking if the unique word exists in a file or not\n",
    "- If it exists then substitute a 1 in term_doc_matrix (eg : TERM_DOC_MATRIX[file][word] = 1 ) \n",
    "- Do the same for all the files present in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary of unique words\n",
      "{'society': 0, 'instance': 1, 'examine': 2, 'Lahore': 3, 'tome': 4, 'Lahore.': 5, 'sample': 6, 'letter': 7, 'dossier': 8, 'my': 9, 'bring': 10, 'question': 11, 'software': 12, 'organization': 13, 'best': 14, 'the': 15, 'forgotten': 16, 'replacement': 17, 'document': 18, 'structure': 19, 'obtain': 20, 'machine': 21, 'favorite': 22, 'mislaid': 23, 'amazing': 24, 'system': 25, 'author': 26, 'at': 27, 'draft': 28, 'back': 29, 'arrangement': 30, 'read': 31, 'interesting': 32, 'am': 33, 'Town': 34, 'application': 35, 'study': 36, 'absorbing': 37, 'missing': 38, 'lost': 39, ':': 40, 'paper': 41, 'platform': 42, 'This': 43, 'fascinating': 44, 'features.': 45, 'device': 46, 'create': 47, 'search': 48, 'look': 49, 'car': 50, 'form': 51, 'example': 52, 'My': 53, 'book': 54, 'framework': 55, 'illustration': 56, 'Range': 57, 'pen': 58, 'publication': 59, 'Hi': 60, 'processor': 61, 'I': 62, 'for': 63, 'file': 64, 'demonstration': 65, 'synonym': 66, 'fetch': 67, 'car.': 68, 'record': 69, 'Hassan': 70, 'program': 71, 'Rover': 72, 'equivalent': 73, 'write': 74, 'fountain': 75, 'retrieve': 76, 'request': 77, 'of': 78, 'recover': 79, 'app': 80, 'ballpoint': 81, 'report': 82, ',': 83, 'explore': 84, 'inquiry': 85, 'peruse': 86, 'ink': 87, 'best.': 88, 'scan': 89, 'volume': 90, 'misplaced': 91, 'novel': 92, 'has': 93, 'alternate': 94, 'query': 95, 'sheet': 96, 'computer': 97, 'Vogue': 98, 'Bahria': 99, 'compose': 100, 'engaging': 101, 'seek': 102, 'is': 103, 'substitute': 104, 'intriguing': 105, 'laptop': 106}\n",
      "Term Document Matrix\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0.\n",
      "  0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0.\n",
      "  1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1.\n",
      "  0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1.\n",
      "  1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here\n",
    "def termDocMatrix(term_doc_matrix):\n",
    "    for i in dictionaryOfFiles().keys():\n",
    "        file_path =  os.path.join('./files', i) #ie complete path /files/f1.txt etc. \n",
    "        with open(file_path,'r') as f:\n",
    "            for line in f: #iterating each line in each file\n",
    "                words = line.split(' ')\n",
    "                for word in words: #iterating each word in each line\n",
    "                    if word in dictionaryOfUniqueWords().keys(): #matching word of file with the uniquewords\n",
    "                        term_doc_matrix[dictionaryOfFiles().get(i),dictionaryOfUniqueWords().get(word)] = 1 \n",
    "    return term_doc_matrix\n",
    "print(f'Dictionary of unique words\\n{dictionaryOfUniqueWords()}')\n",
    "print(f'Term Document Matrix\\n {termDocMatrix(termMatrix())}')\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o4.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 Ask for a user Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For user query make a column vector of length of all the unique words present in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colVector before query\n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here  \n",
    "\n",
    "colVector = np.zeros([len(unique_word_set),1]) #number of rows equals unique_word_set length, in this case we have only one col and multiple rows\n",
    "print(f'colVector before query\\n {colVector}')\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o5.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = input(\"\\nWrite something for searching  \")\n",
    "# Check every word of query if it exists in the set of unique words or not\n",
    "# If exists then increment the count of that word in word dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colVector after query\n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here\n",
    "for word in query.split():\n",
    "    if word in unique_word_set:\n",
    "        colVector[dictionaryOfUniqueWords().get(word),0] += 1\n",
    "print(f'colVector after query\\n {colVector}')\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o6.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 Display Resultant Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display \n",
    "1. Resultant vector.\n",
    "2. Max value in resultant vector.\n",
    "3. Index of max value in resultant vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result \n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "max_index\n",
      "4\n",
      "max\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here  \n",
    "resVector = np.dot(termDocMatrix(termMatrix()),colVector) #matrixMultiplication to get value against each file\n",
    "print(f'result \\n{resVector}')\n",
    "print(f'max_index\\n{np.argmax(resVector)}')\n",
    "print(f'max\\n{max(resVector)}')\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o7.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 Display the contents of file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code to identify the file_name having maximum value in the resultant vector and display its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f5.txt\n",
      "Bahria Town Lahore is the best society of Lahore. Lahore is the best.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here\n",
    "\n",
    "# making keys values and values keys so we can use index as key for particular file\n",
    "\n",
    "fileDictionaryInterchanged = {value: key for key, value in dictionaryOfFiles().items()}\n",
    "if(np.argmax(resVector)>0):  \n",
    "    file = fileDictionaryInterchanged.get(np.argmax(resVector))\n",
    "    print(file)\n",
    "    file_path = os.path.join('./files', file)\n",
    "    with open(file_path,'r') as f:\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(\"No such file with these words\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations Now you are able to build your own small IRS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
